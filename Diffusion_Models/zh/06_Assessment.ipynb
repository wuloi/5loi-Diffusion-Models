{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0a887f",
   "metadata": {},
   "source": [
    "<center><a href=\"https://5loi.com/about_loi\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c238461",
   "metadata": {},
   "source": [
    "# 6. 评估\n",
    "| Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7709a188",
   "metadata": {},
   "source": [
    "恭喜你完成了今天的课程！希望这是一段充满乐趣的旅程，并留下了一些新的技能作为纪念。现在是时候检验这些技能了。\n",
    "\n",
    "在本评估中，挑战是训练一个能够根据 [MNIST 数据集](https://en.wikipedia.org/wiki/MNIST_database) 生成手写图像的新模型。传统上，神经网络会有一个测试数据集，但对于生成式 AI 来说并非如此。美在 beholder 的眼里，作为开发者，过度拟合是否可以接受取决于你。\n",
    "\n",
    "因此，我们创建了一个在 MNIST 数据集上训练的分类器模型。它在 MNIST 测试数据集上的准确率超过 99%。如果这个模型能够正确识别你生成的图像的 95%，你将获得证书！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a8862",
   "metadata": {},
   "source": [
    "## 6.1 数据集\n",
    "| The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da42aa",
   "metadata": {},
   "source": [
    "让我们开始吧，以下是本评估中使用的库。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbae2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "# User defined libraries\n",
    "from utils import other_utils\n",
    "from utils import ddpm_utils\n",
    "from utils import UNet_utils\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc299c",
   "metadata": {},
   "source": [
    "我们之前使用的 FashionMnist 数据集在结构上与 MNIST 类似，因此我们将使用大部分相同的代码来加载它。我们不会随机水平翻转，因为数字通常不应该反向阅读。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MNIST(data_transform, train=True):\n",
    "    return torchvision.datasets.MNIST(\n",
    "        \"./data/\",\n",
    "        download=True,\n",
    "        train=train,\n",
    "        transform=data_transform,\n",
    "    )\n",
    "\n",
    "def load_transformed_MNIST(img_size, batch_size):\n",
    "    data_transforms = [\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),  # Scales data into [0,1]\n",
    "    ]\n",
    "\n",
    "    data_transform = transforms.Compose(data_transforms)\n",
    "    train_set = load_MNIST(data_transform, train=True)\n",
    "    test_set = load_MNIST(data_transform, train=False)\n",
    "    data = torch.utils.data.ConcatDataset([train_set, test_set])\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return data, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0ac69",
   "metadata": {},
   "source": [
    "我们将挑战的分类器模型期望图像大小为 `28x28` 像素。图像也是黑白的。有 `10` 个类别，每个数字对应一个类别。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecc1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 28\n",
    "IMG_CH = 1\n",
    "BATCH_SIZE = 128\n",
    "N_CLASSES = 10\n",
    "data, dataloader = load_transformed_MNIST(IMG_SIZE, BATCH_SIZE)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41101a40",
   "metadata": {},
   "source": [
    "## 6.2 设置扩散\n",
    "| Setting Up Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cddefe0",
   "metadata": {},
   "source": [
    "让我们从设置扩散过程开始。为了节省时间，我们已经在下面列出了 `Beta` 进度表推荐的超参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1960627",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 10\n",
    "ncols = 15\n",
    "\n",
    "T = nrows * ncols\n",
    "B_start = 0.0001\n",
    "B_end = 0.02\n",
    "B = torch.linspace(B_start, B_end, T).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d27cd4",
   "metadata": {},
   "source": [
    "**TODO**: 我们还需要计算我们在  `q` 和 `reverse_q` 函数中将使用的一些变量。你能替换下面的 `FIXME` 吗？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.0 - B\n",
    "a_bar = FIXME(a, dim=0)\n",
    "sqrt_a_bar = FIXME(a_bar)  # Mean Coefficient\n",
    "sqrt_one_minus_a_bar = FIXME(1 - a_bar)  # St. Dev. Coefficient\n",
    "\n",
    "# Reverse diffusion variables\n",
    "sqrt_a_inv = FIXME(1 / a)\n",
    "pred_noise_coeff = (1 - a) / FIXME(1 - a_bar)  # Predicted Noise Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0431c",
   "metadata": {},
   "source": [
    "**TODO**: 下面的 `q` 函数几乎完成了，但我们需要找到图像与噪声的正确比例。这是如何做到的？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x_0, t):\n",
    "        t = t.int()\n",
    "        noise = torch.randn_like(x_0)\n",
    "        sqrt_a_bar_t = sqrt_a_bar[t, None, None, None]\n",
    "        sqrt_one_minus_a_bar_t = sqrt_one_minus_a_bar[t, None, None, None]\n",
    "\n",
    "        x_t = FIXME * x_0 + FIXME * noise\n",
    "        return x_t, noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b885514f",
   "metadata": {},
   "source": [
    "请花点时间验证结果是否符合预期。图像是否从清晰可辨开始，然后消失在噪声中？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc823dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "x_0 = data[0][0].to(device)\n",
    "xs = []\n",
    "\n",
    "for t in range(T):\n",
    "    t_tenser = torch.Tensor([t]).type(torch.int64)\n",
    "    x_t, _ = q(x_0, t_tenser)\n",
    "    img = torch.squeeze(x_t).cpu()\n",
    "    xs.append(img)\n",
    "    ax = plt.subplot(nrows, ncols, t + 1)\n",
    "    ax.axis('off')\n",
    "    other_utils.show_tensor_image(x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb9de5",
   "metadata": {},
   "source": [
    "**TODO**:  `reverse_q` 函数大部分已经完成，但有一些 `FIXME`。每个 `FIXME` 可以是以下之一：\n",
    "* `x_t` - 潜伏图像(latent image)\n",
    "* `t` - 当前时间步(timestep)\n",
    "* `e_t` - 在当前时间步预测的噪声(predicted noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa649bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def reverse_q(x_t, t, e_t):\n",
    "    t = t.int()\n",
    "    pred_noise_coeff_t = pred_noise_coeff[t]\n",
    "    sqrt_a_inv_t = sqrt_a_inv[t]\n",
    "    u_t = sqrt_a_inv_t * (FIXME - pred_noise_coeff_t * FIXME)\n",
    "    if FIXME[0] == 0:  # All t values should be the same\n",
    "        return u_t  # Reverse diffusion complete!\n",
    "    else:\n",
    "        B_t = B[t - 1]  # Apply noise from the previos timestep\n",
    "        new_noise = torch.randn_like(x_t)\n",
    "        return u_t + torch.sqrt(B_t) * new_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84660d9c",
   "metadata": {},
   "source": [
    "## 6.3 设置 U-Net\n",
    "| Setting up a U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689615e1",
   "metadata": {},
   "source": [
    "我们将使用与之前相同的 U-Net 架构：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, T, img_ch, img_size, down_chs=(64, 64, 128), t_embed_dim=8, c_embed_dim=10\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        up_chs = down_chs[::-1]  # Reverse of the down channels\n",
    "        latent_image_size = img_size // 4  # 2 ** (len(down_chs) - 1)\n",
    "        small_group_size = 8\n",
    "        big_group_size = 32\n",
    "\n",
    "        # Inital convolution\n",
    "        self.down0 = ResidualConvBlock(img_ch, down_chs[0], small_group_size)\n",
    "\n",
    "        # Downsample\n",
    "        self.down1 = DownBlock(down_chs[0], down_chs[1], big_group_size)\n",
    "        self.down2 = DownBlock(down_chs[1], down_chs[2], big_group_size)\n",
    "        self.to_vec = nn.Sequential(nn.Flatten(), nn.GELU())\n",
    "\n",
    "        # Embeddings\n",
    "        self.dense_emb = nn.Sequential(\n",
    "            nn.Linear(down_chs[2] * latent_image_size**2, down_chs[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(down_chs[1], down_chs[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(down_chs[1], down_chs[2] * latent_image_size**2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.sinusoidaltime = SinusoidalPositionEmbedBlock(t_embed_dim)\n",
    "        self.t_emb1 = EmbedBlock(t_embed_dim, up_chs[0])\n",
    "        self.t_emb2 = EmbedBlock(t_embed_dim, up_chs[1])\n",
    "        self.c_embed1 = EmbedBlock(c_embed_dim, up_chs[0])\n",
    "        self.c_embed2 = EmbedBlock(c_embed_dim, up_chs[1])\n",
    "\n",
    "        # Upsample\n",
    "        self.up0 = nn.Sequential(\n",
    "            nn.Unflatten(1, (up_chs[0], latent_image_size, latent_image_size)),\n",
    "            GELUConvBlock(up_chs[0], up_chs[0], big_group_size),\n",
    "        )\n",
    "        self.up1 = UpBlock(up_chs[0], up_chs[1], big_group_size)\n",
    "        self.up2 = UpBlock(up_chs[1], up_chs[2], big_group_size)\n",
    "\n",
    "        # Match output channels and one last concatenation\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(2 * up_chs[-1], up_chs[-1], 3, 1, 1),\n",
    "            nn.GroupNorm(small_group_size, up_chs[-1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(up_chs[-1], img_ch, 3, 1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t, c, c_mask):\n",
    "        down0 = self.down0(x)\n",
    "        down1 = self.down1(down0)\n",
    "        down2 = self.down2(down1)\n",
    "        latent_vec = self.to_vec(down2)\n",
    "\n",
    "        latent_vec = self.dense_emb(latent_vec)\n",
    "        t = t.float() / self.T  # Convert from [0, T] to [0, 1]\n",
    "        t = self.sinusoidaltime(t)\n",
    "        t_emb1 = self.t_emb1(t)\n",
    "        t_emb2 = self.t_emb2(t)\n",
    "\n",
    "        c = c * c_mask\n",
    "        c_emb1 = self.c_embed1(c)\n",
    "        c_emb2 = self.c_embed2(c)\n",
    "\n",
    "        up0 = self.up0(latent_vec)\n",
    "        up1 = self.up1(c_emb1 * up0 + t_emb1, down2)\n",
    "        up2 = self.up2(c_emb2 * up1 + t_emb2, down1)\n",
    "        return self.out(torch.cat((up2, down0), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19cb41a",
   "metadata": {},
   "source": [
    "**TODO**: 不幸的是，模块块的名称已经被打乱了。你能根据函数的作用添加正确的模块名称吗？每个模块都有一个：\n",
    "* `GELUConvBlock`\n",
    "* `RearrangePoolBlock`\n",
    "* `DownBlock`\n",
    "* `UpBlock`\n",
    "* `SinusoidalPositionEmbedBlock`\n",
    "* `EmbedBlock`\n",
    "* `ResidualConvBlock`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39004de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, in_chs, out_chs, group_size):\n",
    "        super(DownBlock, self).__init__()\n",
    "        layers = [\n",
    "            GELUConvBlock(in_chs, out_chs, group_size),\n",
    "            GELUConvBlock(out_chs, out_chs, group_size),\n",
    "            RearrangePoolBlock(out_chs, group_size),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a173a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim):\n",
    "        super(EmbedBlock, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, emb_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            nn.Unflatten(1, (emb_dim, 1, 1)),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, group_size):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(in_ch, out_ch, 3, 1, 1),\n",
    "            nn.GroupNorm(group_size, out_ch),\n",
    "            nn.GELU(),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25433f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, in_chs, group_size):\n",
    "        super().__init__()\n",
    "        self.rearrange = Rearrange(\"b c (h p1) (w p2) -> b (c p1 p2) h w\", p1=2, p2=2)\n",
    "        self.conv = GELUConvBlock(4 * in_chs, in_chs, group_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rearrange(x)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, in_chs, out_chs, group_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = GELUConvBlock(in_chs, out_chs, group_size)\n",
    "        self.conv2 = GELUConvBlock(out_chs, out_chs, group_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x1)\n",
    "        out = x1 + x2\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIXME(nn.Module):\n",
    "    def __init__(self, in_chs, out_chs, group_size):\n",
    "        super(UpBlock, self).__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(2 * in_chs, out_chs, 2, 2),\n",
    "            GELUConvBlock(out_chs, out_chs, group_size),\n",
    "            GELUConvBlock(out_chs, out_chs, group_size),\n",
    "            GELUConvBlock(out_chs, out_chs, group_size),\n",
    "            GELUConvBlock(out_chs, out_chs, group_size),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = torch.cat((x, skip), 1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f86ccf",
   "metadata": {},
   "source": [
    "现在所有部分都已定义，让我们定义模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12212e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_utils.UNet(\n",
    "    T, IMG_CH, IMG_SIZE, down_chs=(64, 64, 128), t_embed_dim=8, c_embed_dim=N_CLASSES\n",
    ")\n",
    "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
    "model = torch.compile(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c9d00b",
   "metadata": {},
   "source": [
    "## 6.4 模型训练\n",
    "| Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eef52c",
   "metadata": {},
   "source": [
    "**TODO**: 我们应该创建一个函数来随机丢弃上下文。这个函数是做什么的？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbea63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_mask(c, drop_prob):\n",
    "    c_hot = F.one_hot(c.to(torch.int64), num_classes=N_CLASSES).to(device)\n",
    "    c_mask = torch.FIXME(torch.ones_like(c_hot).float() - drop_prob).to(device)\n",
    "    return c_hot, c_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b239c5cd",
   "metadata": {},
   "source": [
    "**TODO**: 接下来，让我们定义损失函数。我们应该使用什么类型的损失函数？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, x_0, t, *model_args):\n",
    "    x_noisy, noise = q(x_0, t)\n",
    "    noise_pred = model(x_noisy, t/T, *model_args)\n",
    "    return F.FIXME(noise, noise_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268950f",
   "metadata": {},
   "source": [
    "这主要是为了我们的利益，以验证模型是否训练正确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c8cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(model, img_ch, img_size, ncols, *model_args, axis_on=False):\n",
    "    # Noise to generate images from\n",
    "    x_t = torch.randn((1, img_ch, img_size, img_size), device=device)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    hidden_rows = T / ncols\n",
    "    plot_number = 1\n",
    "\n",
    "    # Go from T to 0 removing and adding noise until t = 0\n",
    "    for i in range(0, T)[::-1]:\n",
    "        t = torch.full((1,), i, device=device).float()\n",
    "        e_t = model(x_t, t, *model_args)  # Predicted noise\n",
    "        x_t = reverse_q(x_t, t, e_t)\n",
    "        if i % hidden_rows == 0:\n",
    "            ax = plt.subplot(1, ncols+1, plot_number)\n",
    "            if not axis_on:\n",
    "                ax.axis('off')\n",
    "            other_utils.show_tensor_image(x_t.detach().cpu())\n",
    "            plot_number += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4699bb91",
   "metadata": {},
   "source": [
    "**TODO**:  是时候训练模型了！你能修复 `FIXME` 并开始训练吗？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d272a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "preview_c = 0\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        c_drop_prob = FIXME\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t = torch.randint(0, T, (BATCH_SIZE,), device=device).float()\n",
    "        x = batch[0].to(device)\n",
    "        c_hot, c_mask = get_context_mask(FIXME, c_drop_prob)  # New\n",
    "        loss = get_loss(model, x, t, c_hot, c_mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 1 == 0 and step % 100 == 0:\n",
    "            print(f\"Epoch {epoch} | Step {step:03d} | Loss: {loss.item()} | C: {preview_c}\")\n",
    "            c_drop_prob = 0 # Do not drop context for preview\n",
    "            c_hot, c_mask = get_context_mask(torch.Tensor([preview_c]), c_drop_prob)\n",
    "            sample_images(model, IMG_CH, IMG_SIZE, ncols, c_hot, c_mask)\n",
    "            preview_c = (preview_c + 1) % N_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54422af",
   "metadata": {},
   "source": [
    "## 6.5 采样\n",
    "｜ Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0c0a3",
   "metadata": {},
   "source": [
    "这是拼图的最后一块。我们可以将生成器与分类器进行比较，但就目前而言，它获得 95% 以上准确率的可能性微乎其微。让我们使用 `无分类器扩散引导` 来提高我们的胜算。\n",
    "\n",
    "**TODO**: 下面的 `sample_w` 公式中有一个 `FIXME`。你能记住将权重添加到扩散过程的公式吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_w(model, c, w):\n",
    "    input_size = (IMG_CH, IMG_SIZE, IMG_SIZE)\n",
    "    n_samples = len(c)\n",
    "    w = torch.tensor([w]).float()\n",
    "    w = w[:, None, None, None].to(device)  # Make w broadcastable\n",
    "    x_t = torch.randn(n_samples, *input_size).to(device)\n",
    "\n",
    "    # One c for each w\n",
    "    c = c.repeat(len(w), 1)\n",
    "\n",
    "    # Double the batch\n",
    "    c = c.repeat(2, 1)\n",
    "\n",
    "    # Don't drop context at test time\n",
    "    c_mask = torch.ones_like(c).to(device)\n",
    "    c_mask[n_samples:] = 0.0\n",
    "\n",
    "    x_t_store = []\n",
    "    for i in range(0, T)[::-1]:\n",
    "        # Duplicate t for each sample\n",
    "        t = torch.tensor([i]).to(device)\n",
    "        t = t.repeat(n_samples, 1, 1, 1)\n",
    "\n",
    "        # Double the batch\n",
    "        x_t = x_t.repeat(2, 1, 1, 1)\n",
    "        t = t.repeat(2, 1, 1, 1)\n",
    "\n",
    "        # Find weighted noise\n",
    "        e_t = model(x_t, t, c, c_mask)\n",
    "        e_t_keep_c = e_t[:n_samples]\n",
    "        e_t_drop_c = e_t[n_samples:]\n",
    "        e_t = FIXME\n",
    "\n",
    "        # Deduplicate batch for reverse diffusion\n",
    "        x_t = x_t[:n_samples]\n",
    "        t = t[:n_samples]\n",
    "        x_t = reverse_q(x_t, t, e_t)\n",
    "\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9700cb",
   "metadata": {},
   "source": [
    "**TODO**:  让我们测试一下。试着运行下面的单元格几次。你能通过改变 `w` 使数字始终可识别吗？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06008c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "w = 0.0  # Change me\n",
    "c = torch.arange(N_CLASSES).to(device)\n",
    "c_drop_prob = 0 \n",
    "c_hot, c_mask = get_context_mask(c, c_drop_prob)\n",
    "\n",
    "x_0 = sample_w(model, c_hot, 1.0)\n",
    "other_utils.to_image(make_grid(x_0.cpu(), nrow=N_CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8252f5",
   "metadata": {},
   "source": [
    "这对于自动评分器很重要。输出形状是否为 `[10, 1, 28, 28]`？如果是，你就可以测试模型了！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d76a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d94b2",
   "metadata": {},
   "source": [
    "## 6.6 运行评估\n",
    "｜Run the Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c39033",
   "metadata": {},
   "source": [
    "要评估你的模型，请运行以下两个单元格。\n",
    "\n",
    "**注意:** `run_assessment` 假设你的模型名为 `model` 并且你的扩散权重名为 `w`。如果由于任何原因你修改了这些变量名称，请更新传递给 `run_assessment` 的参数名称。如果你的结果很接近，但还没有达到，请尝试更改上面的 `w`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_assessment import run_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16716acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_assessment(model, sample_w, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067bdb95",
   "metadata": {},
   "source": [
    "## 6.7 生成证书\n",
    "｜Generate a Certificate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a999f918",
   "metadata": {},
   "source": [
    "如果你通过了评估，请返回课程页面（显示在下面）并点击“评估任务”按钮，这将为你生成该课程的证书。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec7413a",
   "metadata": {},
   "source": [
    "<img src=\"./images/assess_task.png\" style=\"width: 800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad1ef34",
   "metadata": {},
   "source": [
    "<center><a href=\"https://5loi.com/about_loi\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
